# Travail Pratique 6 : Introduction au benchmarking de réseaux de neurones artificiels sur des données transcriptomiques de cancers.
## BIN3002 - 30 / 11 / 2023 (séance 1) et 7 / 12 / 2023 (séance 2) </h2>
## 0. Introduction à git et préparation des données. </h2>
Pour une introduction à Git, utilisez la ressource suivante :  <a href="https://learngitbranching.js.org/?locale=fr_FR" target="_blank">Learn git branching</a> 
        <h4>1. Clonez le répertoire de travail git du cours. Faites les ajustements de clé publique, clé privée pour pouvoir activer
            la modification du repo durant la durée du cours. Faites un premier commit en ajoutant un michier selon le format
            <code>script_tp6_NOM1_NOM2.py/ipynb</code>. En rappel, voici la procédure pour push un commit à la branche master du
            github de cours.
        </h4>
            <pre>
            <code class="langugage-bash">
                git clone X 
                git add $FICHIER
                git commit -a -m "added stuff"
                git pull
                git commit -a -m "before push, no changes" # merge commit
                git push # succesful push and merge commit! 
            </code>
        </pre>
        <p>
        Dans cet ordre précis, sans se tromper, ou il faut tout recommencer!
        </p>
        <h2>I. Importation et visualisation des données. </h2>
        <p>
            Les données de TCGA proviennent de ce portail. <a href="https://portal.gdc.cancer.gov/" target="_blank">GDC Data Portal</a>. 
            Les données se trouvent via ce path: <code>/cours/a23_bin3002-a/cours/TP6/*.h5</code>.
        </p>
#### 1. Charger les données en python dans un format matriciel et vectoriel.
#### 2.A Faites une séparation des données d'entrainement des données de test à 20%. Produire la matrice des données d'entrainement en dimension réduite (2D) via UMAP. Utilisez des paramètres n_neighbors et min_dist qui vous semblent appropriés et 1000 itérations. 
        Référez vous à l'exemple suivant. Obtenez les coordonnées des échantillons de test dans le système d'axe 2D offert par UMAP. </h4>
   <pre><code class="language-python">mapper = umap.UMAP(verbose = 1,min_dist=0.5, 
    n_neighbors =20, n_epochs = 1000).fit(X_train)</code></pre>     
#### 2.B ***Générer le graphique des points selon UMAP1 et UMAP2 colorés selon le sous-groupe.***
## II. Création d'un réseau de neurones artificiel pour un problème de régression avec un auto-encodeur.
#### II.1 Créez une fonction qui construit un modèle DNN selon la structure <code>encoder => bottleneck => decoder</code> où la taille d'entrée du modèle (nombre d'inputs) est égale à la taille de sortie. Utilisez la non-linéarité ReLU(), sauf pour la couche centrale qui est linéaire. Créez la boucle d'entrainement. Utilisez la MSE comme loss, optimiseur ADAM, weight decay = 0.001. 
#### II.2 Lancez un entrainement de 1000 epochs et enregistrez la performance du modèle par epoch sous la forme de l'erreur et la correlation de Pearson sur l'ensemble de test et de train.
#### II.3 Produisez la courbe d'apprentissage de l'entrainement de ce réseau, c'est à dire la courbe de l'erreur sur le test et le train et la corrélation de Pearson selon les epochs. 
#### II.4 Faites la visualisation de la corrélation sur les données de test prédites et vraies. <u>Rapportez votre résultat sous la forme d'un histogramme 2D avec des hexagones, l'échelle de la densité doit être rapportées.           
## III. Implémentation d'un Variational Auto-Encoder 
#### III.1 Créez une fonction qui construit un modèle DNN selon la structure <code>VariationalEncoder => bottleneck => Decoder</code> où la taille d'entrée du modèle (nombre d'inputs) est égale à la taille de sortie. Utilisez la non-linéarité ReLU(), sauf pour la couche centrale qui suivra l'architecture d'un VAE. Inspirez-vous du code présent dans le corrigé. Créez la boucle d'entrainement pour le VAE. Utilisez la MSE comme loss, optimiseur ADAM, weight decay = 0.001. Adaptez la fonction de cout par rapport à l'auto-encodeur classique.
            
#### III.2 Lancez un entrainement de 1000 epochs et enregistrez la performance du modèle par epoch sous la forme de l'erreur et la correlation de Pearson sur l'ensemble de test et de train.
#### III.3 Produisez la courbe d'apprentissage de l'entrainement de ce réseau, c'est à dire la courbe de l'erreur sur le test et le train et la corrélation de Pearson selon les epochs. 
#### III.4 Faites la visualisation de la corrélation sur les données de test prédites et vraies. <u>Rapportez votre résultat sous la forme d'un histogramme 2D avec des hexagones, l'échelle de la densité doit être rapportées.
## IV. UMAP supervisé 
#### 2.A Choisissez un jeu de données. Faites une séparation des données d'entrainement des données de test à 20%. Produire la matrice des données d'entrainement en dimension réduite (2D) via UMAP. Utilisez des paramètres n_neighbors et min_dist qui vous semblent appropriés et 1000 itérations. Passez l'argument y à fit avec les étiquettes (labels). Référez vous à l'exemple suivant. Obtenez les coordonnées des échantillons de test dans le système d'axe 2D offert par UMAP. 
   <pre><code class="language-python">mapper = umap.UMAP(verbose = 1,min_dist=0.5, 
    n_neighbors =20, n_epochs = 1000).fit(X_train, y = labels)</code></pre>      
#### 2.B  Générer le graphique des points du test et du train selon UMAP1 et UMAP2 colorés selon le sous-groupe.
## V. Présentation des projets
### 1. Régression et classification, quelle méthode utiliser et pourquoi?
#### A. Testez les modèles suivants SVM, RF, Logistic, DNN pour la classification des sous-types moléculaires de BRCA, LAML, TALL.  
#### B. Testez les modèles suivants Auto-Encodeurs, VAE, RF, SVM, et la régression logistique pour la prédiction de l'expression de tous les gènes des jeux de données. Quels sont les paramètres utilisés? Répétez les expériences 10 fois et rapportez la moyenne et l'écart type des performances sur le test. Rapportez les temps de calculs sur CPU.
### 2. Hyper-paramétrisation et comparaison des performances des auto-encodeurs et des VAE pour la régression sur de vraies données transcriptomiques des cancers. 
#### A. Investiguer la l2, la taille du bottleneck. faire varier taille reste réseau. Quels sont les paramètres idéaux? Quelle est la taille de bottleneck idéale?  Quels sont les paramètres sensibles? </h5>
#### B. Comparaison des performances entre les méthodes  VAE vs AE vs UMAP suivants TCGA, TCGA-BRCA, Leucegene-AML, TALL. Quelle méthode fonctionne le mieux et pourquoi? </h5>    
### 3. Création de jeux de données  transcriptomiques synthétiques et sur des données transcriptomiques chimériques 
#### A. Création d'un jeu de données synthétiques. Créez deux jeux de données synthétiques permettant de comprendre les forces et les faiblesses de chaque méthode. Comparaison des performances entre les méthodes pour la classification moléculaires et la régression. Quelle méthode fonctionne le mieux et pourquoi?
#### B. Montez un protocole experimental pour créer un jeu de données synthétique en combinant deux sous-groupes de TCGA avec une tâche prédictive associée et testez les architectures proposées. Qu'en concluez-vous?
### 4. Développement d'un algorithme de réduction de dimensionnalité de projection en coordonnées sphériques pour une visualisation plus représentative. 
#### A. Proposez une approche qui permet une telle visualisation. 
#### B. Trouvez une métrique de distance intra-groupe, et extra-groupe qui permet de comparer ces visualisaitons avec les visualisations classiques. Que vient apporter cette méthode? 
### 5. Comparaison des performances entre les méthodes linéaires vs méthodes non-linéaires pour la prédiction sur de vraies données transcriptomiques des cancers de TCGA. 
#### A. Pour la classification moléculaires entre la régression linéaire et un DNN, quelle méthode fonctionne le mieux et pourquoi?
#### B. Pour la régression entre la régression linéaire et un Auto-Encodeur, quelle méthode fonctionne le mieux et pourquoi?
#### C. Démontrez qu'une PCA 2D est équivalent à la couche interne bottleneck d'Auto-Encodeur linéaire.

### 6. AE et VAE supervisé vs UMAP - Classification - Comparaison des performances entre les méthodes pour la classification moléculaires et la régression sur de vraies données transcriptomiques des cancers suivants TCGA, TCGA-BRCA, Leucegene-AML, TALL. Quelle méthode fonctionne le mieux et pourquoi? 


