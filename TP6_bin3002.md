# Travail Pratique 6 : Introduction au benchmarking de réseaux de neurones artificiels sur des données transcriptomiques de cancers.
### BIN3002 - 30 / 11 / 2023 (séance 1) et 7 / 12 / 2023 (séance 2)
## Partie 1 : rédaction de l'annexe de votre résumé (50%)
Dans cette section, nous allons nous familiariser avec les méthodes et les données qui seront testées lors de ce travail pratique. Le but est de générer les figures qui serviront à remplir l'annexe de votre résumé. Les section I-IV seront évaluées vie les figures annotées qui seront générées. ***Toutes les lignes en italiques sont des figures qui seront évaluées!***

Le format de votre annexe est le suivant: **1) Données** : Pour chaque jeu de donnée (4), rapportez le nombre d'échantillons, de gènes, et le nombre de classes d'étiquettes à prédire.  **2) Méthodes** : pour chaque section II,III,IV, vous devez A) Écrire une courte intro qui explique qui a développé la méthode et pour quoi on l'utilise. Inclure une référence à un article et à la documentation du programme. B) Montrer un exemple d'utilisation avec des figures du notebook. 

## 0. Introduction à git et préparation des données. </h2>
Pour une introduction à Git, utilisez la ressource suivante :  <a href="https://learngitbranching.js.org/?locale=fr_FR" target="_blank">Learn git branching</a> 
#### 1. Clonez le répertoire de travail git du cours. Faites les ajustements de clé publique, clé privée pour pouvoir activer la modification du repo durant la durée du cours. Faites un premier commit en ajoutant un michier selon le format <code>script_tp6_NOM1_NOM2.py/ipynb</code>. En rappel, voici la procédure pour push un commit à la branche master du github de cours.
<pre>
<code class="langugage-bash">
git clone X 
git add $FICHIER
git commit -a -m "added stuff"
git pull
git commit -a -m "before push, no changes" # merge commit
git push # succesful push and merge commit! 
</code>
</pre>
Dans cet ordre précis, sans se tromper, ou il faut tout recommencer!
        
## I. Importation et visualisation des données. 
Les données de TCGA proviennent de ce portail. <a href="https://portal.gdc.cancer.gov/" target="_blank">GDC Data Portal</a>. Les données se trouvent via ce path: <code>/cours/a23_bin3002-a/cours/TP6/*.h5</code>.
#### 1. Charger les données en python dans un format matriciel et vectoriel.
#### 2.A Faites une séparation des données d'entrainement des données de test à 20%. Produire la matrice des données d'entrainement en dimension réduite (2D) via UMAP. Utilisez des paramètres n_neighbors et min_dist qui vous semblent appropriés et 1000 itérations. 
Référez vous à l'exemple suivant. Obtenez les coordonnées des échantillons de test dans le système d'axe 2D offert par UMAP. 
   <pre><code class="language-python">mapper = umap.UMAP(verbose = 1,min_dist=0.5, 
    n_neighbors =20, n_epochs = 1000).fit(X_train)</code></pre>     
#### 2.B ***Générer le graphique des points selon UMAP1 et UMAP2 colorés selon le sous-groupe.***
## II. Création d'un réseau de neurones artificiel pour un problème de régression avec un auto-encodeur.
#### II.1 Créez une fonction qui construit un modèle DNN selon la structure <code>encoder => bottleneck => decoder</code> où la taille d'entrée du modèle (nombre d'inputs) est égale à la taille de sortie. Utilisez la non-linéarité ReLU(), sauf pour la couche centrale qui est linéaire. Créez la boucle d'entrainement. Utilisez la MSE comme loss, optimiseur ADAM, weight decay = 0.001. 
#### II.2 Lancez un entrainement de 1000 epochs et enregistrez la performance du modèle par epoch sous la forme de l'erreur et la correlation de Pearson sur l'ensemble de test et de train.
#### II.3 ***Produisez la courbe d'apprentissage de l'entrainement de ce réseau, c'est à dire la courbe de l'erreur sur le test et le train et la corrélation de Pearson selon les epochs.*** 
#### II.4 Faites la visualisation de la corrélation sur les données de test prédites et vraies. ***Rapportez votre résultat sous la forme d'un histogramme 2D avec des hexagones, l'échelle de la densité doit être rapportées.***           
## III. Implémentation d'un Variational Auto-Encoder 
#### III.1 Créez une fonction qui construit un modèle DNN selon la structure <code>VariationalEncoder => bottleneck => Decoder</code> où la taille d'entrée du modèle (nombre d'inputs) est égale à la taille de sortie. Utilisez la non-linéarité ReLU(), sauf pour la couche centrale qui suivra l'architecture d'un VAE. Inspirez-vous du code présent dans le corrigé. Créez la boucle d'entrainement pour le VAE. Utilisez la MSE comme loss, optimiseur ADAM, weight decay = 0.001. Adaptez la fonction de cout par rapport à l'auto-encodeur classique.
#### III.2 Lancez un entrainement de 1000 epochs et enregistrez la performance du modèle par epoch sous la forme de l'erreur et la correlation de Pearson sur l'ensemble de test et de train.
#### III.3 ***Produisez la courbe d'apprentissage de l'entrainement de ce réseau, c'est à dire la courbe de l'erreur sur le test et le train et la corrélation de Pearson selon les epochs.*** 
#### III.4 Faites la visualisation de la corrélation sur les données de test prédites et vraies.  ***Rapportez votre résultat sous la forme d'un histogramme 2D avec des hexagones, l'échelle de la densité doit être rapportées.***
## IV. UMAP supervisé 
#### 2.A Choisissez un jeu de données. Faites une séparation des données d'entrainement des données de test à 20%. Produire la matrice des données d'entrainement en dimension réduite (2D) via UMAP. Utilisez des paramètres n_neighbors et min_dist qui vous semblent appropriés et 1000 itérations. Passez l'argument y à fit avec les étiquettes (labels). Référez vous à l'exemple suivant. Obtenez les coordonnées des échantillons de test dans le système d'axe 2D offert par UMAP. 
   <pre><code class="language-python">mapper = umap.UMAP(verbose = 1,min_dist=0.5, 
    n_neighbors =20, n_epochs = 1000).fit(X_train, y = labels)</code></pre>      
#### 2.B  ***Générer le graphique des points du test et du train selon UMAP1 et UMAP2 colorés selon le sous-groupe.***
## Partie 2: Présentation des projets (50%)
### 0. Directives pour le projet.
Pour chaque mini-projet, le but est de répondre aux sous-objectifs demandés via une expérience. Pour chaque expérience, expliquez son but et la raison d'explorer la question. Vous devez ensuite générer les résultats et les présenter sous la forme d'un ou plusieurs graphiques correctement annotés. La figure doit être analysée et la conclusion de l'expérience énoncée. De plus, le format d'écriture du résumé devra respecter la forme suivante: **Texte continu contenant une introduction, résultats et conclusions et perspectives + références de maximum 2 pages**. Les figures générées dans les sections I-IV de ce notebook serviront à créer l'annexe de votre résumé intitulé **TP6_data_methods_NOM1_NOM2.pdf**. 
### 1. Régression et classification, quelle méthode utiliser et pourquoi?
Répétez les expériences 10 fois et rapportez la moyenne et l'écart type des performances sur le test. Rapportez les temps de calculs sur CPU.
#### A. Testez les modèles suivants SVM, RF, Logistic, DNN pour la classification des sous-types moléculaires de BRCA, LAML, TALL et TCGA.  
#### B. Testez les modèles suivants Auto-Encodeurs, VAE, RF, SVM, et la régression logistique pour la prédiction de l'expression de tous les gènes des jeux de données. Quels sont les paramètres utilisés? 
### 2. Hyper-paramétrisation et comparaison des performances des auto-encodeurs et des VAE pour la régression sur de vraies données transcriptomiques des cancers. 
#### A. Fixez la taille des couches internes des réseaux. Investiguer rapidement l'impact des paramètres L2 (weight decay), du learning rate, puis fixez ces paramètres. Faites varier la taille du bottleneck de l'AE et du VAE avec les valeurs [1,2,3,5,10,15,20,25,30,50,75,100,125,150,200,300].  Quels sont les paramètres idéaux? Quelle est la taille de bottleneck idéale?  Quels sont les paramètres sensibles? Qu'en concluez-vous?
#### B. Comparaison des performances entre les méthodes  VAE vs AE vs UMAP suivants TCGA, TCGA-BRCA, Leucegene-AML, TALL. Quelle méthode fonctionne le mieux et pourquoi?   
### 3. Création de jeux de données  transcriptomiques synthétiques et sur des données transcriptomiques chimériques 
#### A. Création d'un jeu de données synthétiques. Créez deux jeux de données synthétiques permettant de comprendre les forces et les faiblesses de chaque méthode. Comparaison des performances entre les méthodes pour la classification moléculaires et la régression. Quelle méthode fonctionne le mieux et pourquoi?
#### B. Montez un protocole experimental pour créer un jeu de données synthétique en combinant deux sous-groupes de TCGA avec une tâche prédictive associée et testez les architectures proposées. Qu'en concluez-vous?
### 4. Développement d'un algorithme de réduction de dimensionnalité de projection en coordonnées sphériques pour une visualisation plus représentative. 
#### A. Proposez une approche qui permet une telle visualisation. 
#### B. Trouvez une métrique de distance intra-groupe, et extra-groupe qui permet de comparer ces visualisaitons avec les visualisations classiques. Que vient apporter cette méthode? 
### 5. Comparaison des performances entre les méthodes linéaires vs méthodes non-linéaires pour la prédiction sur de vraies données transcriptomiques des cancers de TCGA. 
#### A. Pour la classification moléculaires entre la régression linéaire et un DNN, quelle méthode fonctionne le mieux et pourquoi?
#### B. Pour la régression entre la régression linéaire et un Auto-Encodeur, quelle méthode fonctionne le mieux et pourquoi?
#### C. Démontrez qu'une PCA 2D est équivalent à la couche interne bottleneck d'Auto-Encodeur linéaire.

### 6. AE et VAE supervisé vs UMAP - Classification - Comparaison des performances entre les méthodes pour la classification moléculaires et la régression sur de vraies données transcriptomiques des cancers suivants TCGA, TCGA-BRCA, Leucegene-AML, TALL. Quelle méthode fonctionne le mieux et pourquoi? 


