<body>
    <div class="container">
        <h1>Travail Pratique 6 : Introduction au benchmarking de réseaux de neurones artificiels sur des données transcriptomiques de cancers.</h1>
        <h2>BIN3002 - 30 / 11 / 2023 (séance 1) et 7 / 12 / 2023 (séance 2) </h2>
        <h3>0. Introduction à git et préparation des données. </h3>
        ­<p>Pour une introduction à Git, utilisez la ressource suivante :  <a href="https://learngitbranching.js.org/?locale=fr_FR" target="_blank">Learn git branching</a> </p>
        <h4>1. Clonez le répertoire de travail git du cours. Faites les ajustements de clé publique, clé privée pour pouvoir activer
            la modification du repo durant la durée du cours. Faites un premier commit en ajoutant un michier selon le format
            <code>script_tp6_NOM1_NOM2.py/ipynb</code>. En rappel, voici la procédure pour push un commit à la branche master du
            github de cours.
        </h4>
            <pre>
            <code class="langugage-bash">
                git clone X 
                git add $FICHIER
                git commit -a -m "added stuff"
                git pull
                git commit -a -m "before push, no changes" # merge commit
                git push # succesful push and merge commit! 
            </code>
        </pre>
        <p>
        Dans cet ordre précis, sans se tromper, ou il faut tout recommencer!
        </p>
        <h3>I. Introduction aux tâches de regréssion avec un auto-encodeur.</h3>
        <p>
            Les données de TCGA proviennent de ce portail. <a href="https://portal.gdc.cancer.gov/" target="_blank">GDC Data Portal</a>. 
            Les données se trouvent via ce path: <code>/cours/a23_bin3002-a/cours/TP5/TCGA_TPM_hv_subset.h5</code>.
        </p>
        <h4>1. Charger les données en python dans un format matriciel et vectoriel.</h4>
        <h4>2.A Faites une séparation des données d'entrainement des données de test à 20%. Produire la matrice des données d'entrainement en dimension réduite (2D) via UMAP. Utilisez un <code>n_neighbors=200</code> et 1000 itérations. 
        Référez vous à l'exemple suivant. Obtenez les coordonnées des échantillons de test dans le système d'axe 2D offert par UMAP. </h4>
   <pre><code class="language-python">mapper = umap.UMAP(verbose = 1,min_dist=1., 
    n_neighbors =200, n_epochs = 1000).fit(X_train)</code></pre>     
        <h4>2.B  <u>Générer le graphique des points selon UMAP1 et UMAP2 colorés selon le sous-groupe.</u></h4>
        <h3>II. Création d'un réseau de neurones artificiel pour un problème de régression avec un auto-encodeur. 
            <h4>II.1 Créez une fonction qui construit un modèle DNN selon la structure <code>encoder => bottleneck => decoder</code>
            où la taille d'entrée du modèle (nombre d'inputs) est égale à la taille de sortie. Utilisez
            la non-linéarité ReLU(). sauf pour la couche centrale qui est linéaire. Créez la boucle d'entrainement. Utilisez
            la MSE comme loss, optimiseur ADAM, weight decay = 0.001. 
            </h4>
            <h4>II.2 Lancez un entrainement de 1000 epochs et enregistrez la performance du modèle par epoch sous la forme de l'erreur et la correlation 
                de Pearson sur l'ensemble de test et de train.</h4>
            <h4>
                <u>II.3 Produisez la courbe d'apprentissage de l'entrainement de ce réseau, c'est à dire la courbe de l'erreur sur le 
                test et le train et la corrélation de Pearson selon les epochs. </u>
            </h4>
                <h4>II.4 Faites la visualisation de la corrélation sur les données de test prédites et vraies. <u>Rapportez votre résultat sous la 
                forme d'un histogramme 2D avec des hexagones, l'échelle de la densité doit être rapportées.</u>   
            </h4>
        <h3>III. VAE </h3>
        <h3>IV. UMAP supervisé </h3>
        <h3>V. AE supervisé</h3>
        <h3>VI. VAE supervisé </h3>
        <h3>VII. VAE vs AE vs UMAP - Classification et régression - benchmarking partie 1</h3>
        <h3>Présentation des projets</h3>
        <h4>1. Comparaison des performances entre les 3 méthodes pour la classification moléculaires et la régression sur de 
            vraies données transcriptomiques des cancers suivants TCGA, TCGA-BRCA, Leucegene-AML. Quelle méthode fonctionne le mieux et pourquoi?
        </h4>
        <h4>2. Comparaison des performances entre les 3 méthodes pour la classification moléculaires et la régression sur des 
            données transcriptomiques synthétiques. Quelle méthode fonctionne le mieux et pourquoi?
        </h4>
        <h4>3. Développement d'un algorithme de réduction de dimensionnalité de projection en coordonnées sphériques pour une 
            visualisation plus représentative. Que vient apporter cette méthode? </h4>
            <h5>a. AE(Sphere)+DNN vs AE+DNN vs UMAP+KNN </h5>
            <h5>b. synthéthiques / TCGA-BRCA / TCGA</h5>
            <h5>c. capable de projeter nouvelles données, doit mieux respecter les distances.</h5>
            <h5>d. visualisations pseudo 3D.</h5>
        <h4>4. Comparaison des performances entre les 3 méthodes vs méthodes linéaires.pour la classification moléculaires et la régression sur de 
            vraies données transcriptomiques des cancers de TCGA. Quelle méthode fonctionne le mieux et pourquoi?</h4>
        <h4>5. Comparaison des performances entre les 3 méthodes pour la classification moléculaires et la régression sur des 
            données transcriptomiques chimériques (combinaisons de jeux de données). Quelle méthode fonctionne le mieux et pourquoi? </h4>
        <h4>6. Hyper-paramétrisation du VAE et du VAE supervisé. Quels sont les paramètres idéaux?</h4>
        <h5>a. requiert usage de la GPU. Cross-validation x 10 replicat.</h5>
        <h5>b. investiguer la l2, la taille du bottleneck. faire varier taille reste réseau.</h5>
        <h4>7. Hyper-paramétrisation du VA et du VA+DNN supervisé. Quelle est la taille de
            bottleneck idéale? Quels sont les paramètres sensibles?</h4>
        <h5>a. requiert usage de la GPU. Cross-validation x 10 replicat.</h5>
        <h5>b. investiguer la l2, la taille du bottleneck. faire varier taille reste réseau. 
        </h5>
        <h4>8. Régression et classification, quelle méthode utiliser? </h4>
        <h5>Classification: SVM, RF, Logistic, DNN, AE+DNN, VAE+DNN</h5>
        <h5>Régression: DNN, RF, SVM, </h5>
        <h5>computing time.</h5>
    </div>
</body>
